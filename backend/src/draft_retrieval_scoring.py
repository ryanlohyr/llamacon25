# Load the libraries
from sentence_transformers import SentenceTransformer, util
import faiss
import json
import uuid

# We need to define a function to decide whether the code was buggy or not

POSITIVE_SEMANTIC_INTENTS = [
    "that fixed it",
    "it's working now",
    "solved it",
    "thanks, it works",
    "no more errors",
    "this helped",
    "it runs correctly",
    "you nailed it"]

NEGATIVE_SEMANTIC_INTENTS = [
        # We can add more templates here
        # These are some I got from ChatGPT
        "It's still broken",
        "Now I get a different error",
        "Still doesn't work",
        "I'm getting a traceback",
        "Why is it failing?",
        "It crashes",
        "SyntaxError",
        "This gives an exception",
        "I get an error"]

embedder = SentenceTransformer("all-MiniLM-L6-v2")

def is_negative_feedback(user_query):
    #Return True if the user's question implies failure, error, or confusion

    # Get the embedding of user query
  
    query_emb = embedder.encode(user_query, convert_to_tensor=True)
    
    example_embs = embedder.encode(NEGATIVE_SEMANTIC_INTENTS, convert_to_tensor=True)
  
    similarity = util.cos_sim(query_emb, example_embs)
    # Using Cosine similarity to check the similarity between failure and user feedback
  
    return similarity.max() > 0.6 
    # tune

def is_positive_feedback(user_query):
    query_emb = embedder.encode(user_query, convert_to_tensor=True)
    examples = embedder.encode(POSITIVE_SEMANTIC_INTENTS, convert_to_tensor=True)
    similarity = util.cos_sim(query_emb, examples)
    return similarity.max() > 0.6 
   # tune threshold if needed


def session_outcome(session):
    error_count = sum(1 for turn in session["question_chain"] if is_negative_feedback(turn["q"]))
    
    last_q = session["question_chain"][-1]["q"]

    if is_positive_feedback(last_q):
        final_output = "Success"
        tests_passed = True
    elif error_count > 0:
        final_output = "Error"
        tests_passed = False
    else:
        final_output = "Unknown"
        tests_passed = False

    return final_output, tests_passed, error_count
  

def reward(session):
    final_output, tests_passed, error_count = session_outcome(session)
    session["final_output"] = final_output
    session["tests_passed"] = tests_passed
    session["error_count"] = error_count
    # Length of Chain --- longer the worse
    session["chain_length"] = len(session["question_chain"])

    if tests_passed:
        return 1.0
    elif error_count > 0:
        return -0.5
    elif session["chain_length"] > 10:
        return -0.3
    else:
        return 0.0

# Session memory is a json file of past chat history --- Generated by ChatGPT

# We need to create a synthetic data set of this
session_memory = [
    {
        "session_id": "fix-cors-001",
        "initial_question": "How do I fix a CORS error in Flask?",
        "question_chain": [
            {"q": "How do I fix a CORS error in Flask?", "a": "Try using Flask-CORS."},
            {"q": "How to install it?", "a": "Run `pip install flask-cors`."},
            {"q": "How to configure it?", "a": "Use `CORS(app)` after creating the app."},
            {"q": "Great, that worked!", "a": "Glad to hear it!"}
        ],
        "final_code": "from flask import Flask\nfrom flask_cors import CORS\napp = Flask(__name__)\nCORS(app)"
    },
    {
        "session_id": "broken-import-001",
        "initial_question": "Why does my import keep failing?",
        "question_chain": [
            {"q": "Why does my import keep failing?", "a": "Make sure the module is installed."},
            {"q": "It still gives an error", "a": "Check if it's in your PYTHONPATH."},
            {"q": "Now I get a different error", "a": "Try restarting your environment."}
        ],
        "final_code": "import non_existent_module"
    }
]

# Session memory can be liaded

file_path = # Set it to the Json file
with open(file_path, 'r') as file:
    session_memory = [json.loads(line) for line in file]
    
for s in session_memory:
    s["score"] = reward(s)

# IMPORTANT: Anchor/summary of the session
questions = [s["initial_question"] for s in session_memory]

embeddings = embedder.encode(questions)
# Index the embedding using brute force

index = faiss.IndexFlatL2(len(embeddings[0]))
index.add(embeddings)

def find_best_chain(query):
    query_vec = embedder.encode([query])
    # top k is tunable
    D, I = index.search(query_vec, k=5)
    top_sessions = sorted([session_memory[i] for i in I[0]], key=lambda s: -s["score"])
    return top_sessions[0]

def build_prompt_from_chain(chain, new_question):
    # This is a basic promt generator built from chatGPT. It needs to be integrated with Meta Prompt from Chris
    chat_log = "\n".join([f"Q: {turn['q']}\nA: {turn['a']}" for turn in chain["question_chain"]])
    return f"""Previously, a user had a similar problem. Here's how they solved it:

{chat_log}

Final working code:
{chain['final_code']}

Now answer this new question:
{new_question}
"""

####  Run ###


user_q = # get it from the API
best = find_best_chain(user_q)
prompt = build_prompt_from_chain(best, user_q)


